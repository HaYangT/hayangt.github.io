---
title: "프로젝트 속에 AI를 녹여 담았던 과정"
date: 2026-02-13
categories: [Blog]
tags: [프로젝트]
pin: false
---

# 개요
HearO는 AI기능에 의존하는 프로젝트다. 그래서 나는 서비스 속에 자연스럽게 녹일 방법을 생각해보았다. AI를 숨겨야한다는 것은 아니다. 우리의 서비스 속에 자연스럽게 녹아 이질감이 들지 않아야 한다는 것이다.

---
## 일렉트론으로 포장

원래는 AI도 EC2에 배포해서 사용할까 고민했다. 하지만 우리는 속도가 생명이였기 때문에 결국 빠른 로컬 서버로 AI를 띄워서 통신하기로 했다. 그러는 과정에서 사용자들의 손쉬운 접근과 사용이 필요하다 느껴서 데스크톱 앱을 만들기로 했고, 그렇게 Electron을 사용하게 되었다.

Electron은 웹앱을 통째로 프로그램처럼 포장해주는 도구로, 로컬 AI서버와 웹을 동시에 실행시키기 위해 사용했다. 포장된 파일을 실행하면 AI서버에 계속 헬스체크를 시도한다. 헬스체크 응답이 200이 될때까지 프론트 화면을 띄우지 않다가 200응답이 오면 그제서야 프론트 화면을 띄웠다.

```js
app.whenReady().then(async () => {
  app.setAppUserModelId("com.ssafy.HearO");

  createSplash();
  startAiServer();

  const ok = await waitForHealth(60000, 500);
  if (!ok) console.error("[AI] health check timeout:", AI_HEALTH_URL);

  createMain();
});

```

createSplash() 함수는 AI 서버가 실행되는 동안 보여지는 스피너 화면을 띄우는 함수다. 이 화면이 띄워짐과 동시에 exe파일로 만들어둔 AI서버를 실행한다. 그렇게 헬스체크가 끝나면 createMain() 함수를 실행하면서 메인 페이지를 로드한다. 

Electron을 사용하면서 로컬 AI 서버의 생명주기를 관리함에 따라 사용자의 불편함을 해소하고 서비스 오류를 방지할 수 있었다.

---

## Spring AI 

Spring AI는 들어보기만 하고, 실제로 사용해본적은 없었다. 처음에는 Spring에 내장되어있는 AI인가? 라는 생각을 했지만, 실제로는 AI 기능을 호출하고 조율하기 위한 역할을 가진 프레임워크였다.

우리의 프로젝트는 RAG와 통화 요약등, LLM API들을 사용한 텍스트 생성과 요약, 추론 기능을 사용해야했다. 하지만 우리는 Electron을 사용한 데스크톱 앱을 사용해야 했기에, 코드에 API_KEY를 박아넣었다간 무슨 참사가 발생할 지 안봐도 알 수 있었다. 

그래서 나는 보안성을 확보하면서도, AI 로직을 효율적으로 관리하기 위해 Spring AI를 사용하여 호출을 표준화 한뒤에 외부 LLM와 연동했다.

Controller와 Service는 다른 CRUD와 동일하지만, 외부 LLM 호출은 Client/Adapter 계층으로 분리하여 독립적으로 시행되게 했다.

자세한 흐름들은 기능별로 아래에 설명해놓겠다.

---

## 통화 내용 요약 관련 이슈와 해결

초기 설계에서는 고객과 상담사의 발화를 모두 STT로 변환하여 기록하려 했다. 상담사의 발화는 상담사 화면에서, 고객의 발화는 고객 화면에서 각각 STT를 생성한 뒤 이를 저장하는 구조였다. Chrome 환경에서 테스트했을 때는 이 방식이 문제없이 동작했다.

하지만 Electron으로 앱을 패키징하는 과정에서 STT 기능이 정상적으로 동작하지 않는 문제가 발생했다. 보안 정책이나 오리진 제한으로 인해 브라우저 환경과 동일하게 마이크 접근이 허용되지 않았던 것으로 보인다. 그렇다고 Electron 환경을 포기할 수는 없었다. 자연스럽게 AI 기능을 녹여내기 위해서는 데스크톱 앱 형태가 필요했기 때문이다. 결국 상담사의 발화는 STT 대신, 상담사가 직접 메모하듯 입력하는 방식으로 방향을 전환했다.

통화 내용을 기록하는 주된 목적은 상담사가 하루 동안의 상담 내용을 보다 수월하게 정리할 수 있도록 AI 요약을 제공하기 위함이었다. SSAFY에서 제공되는 충분한 토큰을 활용해, AI 요약 기능은 Spring AI를 통해 외부 LLM을 호출하는 방식으로 구현했다. 모델은 속도와 비용을 고려해 경량화된 gpt-4.1 mini를 사용했다.

초기 구현에는 통화 종료 시점에 상담 데이터를 POST로 생성한 뒤, 해당 데이터를 기반으로 AI 요약을 생성하는 구조였다. 하지만 한가지 문제가 있었다. 이 과정에서 AI 요약이 생성되는 데 일정 시간이 소요되었고, 그
사이 고객이 설문조사를 먼저 제출하는 경우 문제가 발생했다. 아직 상담 데이터가 생성되지 않은 상태였기 때문에, 설문조사 요청에서 참조하던 상담 ID가 null이 되어 에러가 발생한 것이다. 이건 단순한 예외 처리로 해결할 수 있는 문제가 아닌, 트랜잭션 경계가 잘못 설정된 구조적 문제라고 판단했다.

이를 해결하기 위해서 일부 NOT NULL 칼럼을 NULLABLE로 바꾼 후, 
상담 데이터 생성을 두단계로 분리했다. 상담사와 고객이 매칭됨과 동시에 필요한 최소정보로만 POST를 호출해 데이터를 생성하고, 상담 종료 이후 POST 호출 부분은 PATCH로 변경하며 부족한 데이터를 채웠다.

이러한 구조 변경을 통해 각 기능은 서로 독립적인 트랜잭션으로 처리될 수 있었고, 특정 기능의 지연이나 실패가 전체 흐름에 영향을 주지 않도록 만들 수 있었다. 특히 외부 AI 호출과 같이 지연 가능성이 높은 작업을 핵심 트랜잭션에서 분리함으로써 데이터 정합성과 사용자 경험을 동시에 화곱할 수 있었다.

완성된 전체흐름은 다음과 같다.

```css
STT 전체 텍스트
        ↓
[ Summary Service ]
   - 텍스트 정제
   - 길이 조절
        ↓
[ Spring AI ]
   - 요약 전용 Prompt
   - 추측 금지 정책
        ↓
[ LLM ]
        ↓
구조화된 요약
(title / subtitle / summary)
        ↓
DB 저장
```

---

## RAG 

단순히 LLM에게 질문을 던지는 방식은 상담 도메인에서는 위험했다. 모델이 환각현상을 일으키는 경우가 있어 상담사가 이를 그대로 신뢰할 가능성도 있었다.

따라서 답변의 근거를 명확하게 하기 위해 문서를 먼저 검색한 뒤 그 문서만을 기반으로 답변하도록 하는 RAG 구조를 선택했다.

RAG는 정말 많은 우여곡절이 있었던 것 같다. 배포된 docker에 문서를 임베딩해서 넣는것도 어려웠다. 임베딩을 위한 가상환경을 계속 새로 만들면서 의존성 지옥에서 벗어나기 위해 많은 시간이 들었다.

RAG도 대화요약 기능과 마찬가지로 외부 LLM을 사용했다. 임베딩 모델은 text-embedding-3-small을 사용했으며, 추론은 동일하게 gpt-4.1-mini를 사용했다.

전체적인 흐름은 다음과 같다
```css
[ 상담사 질문 입력 ]
        ↓
POST /rag/ask
        ↓
[ Spring Backend ]
        ↓
[ AI Server (Spring AI) ]
   ├─ 질문 임베딩
   ├─ Vector DB 검색
   ├─ Prompt 구성
   └─ LLM 호출
        ↓
답변 + 근거 문서
        ↓
상담사 화면 표시

```
작성한 프롬프트는 다음과 같다

```text
"""
                너는 고객지원 문서를 기반으로 답변하는 RAG 어시스턴트다.
                아래 [CONTEXT]에 포함된 정보만 사용해서 답변하라.
                컨텍스트에 없는 사실/수치/절차/코드/정책은 절대 추측하지 말고 반드시
                "컨텍스트에 정보가 없습니다." 라고 말하라.
                
                [핵심 규칙]
                1) 컨텍스트에 있는 내용만 인용/재구성해서 답하라. 상식/추측/외부지식 금지.
                2) 질문이 모호하면, 컨텍스트에서 확인 가능한 범위만 말하고 "추가로 필요한 정보"를 1~3개 질문하라.
                3) 답변을 만들기 전에, 컨텍스트가 질문을 해결하기에 충분한지 스스로 점검하라.
                   - 충분하지 않으면 답변 대신 "컨텍스트에 정보가 없습니다." 를 출력하라.
                4) 숫자, 모델명, 오류코드, 전화번호, 운영시간 등은 컨텍스트에 나온 그대로만 사용하라.
                5) 컨텍스트에 없는 항목을 나열하거나, "다음과 같습니다" 식으로 개수를 꾸며내지 말라.
                6) 답변은 한문단으로 하여라.
                
                [출력 형식 - 반드시 지켜라]
                아래 JSON 형식으로만 출력하라(마크다운 금지).
                
                {
                  "answer": "최종 답변(한국어). 짧고 명확하게.",
                  "evidence": [
                    {
                      "source": "<파일명 또는 source>",
                      "quote": "<컨텍스트에서 그대로 가져온 근거 문장(최대 25단어)>"
                    }
                  ],
                  "need_more_info": [
                    "컨텍스트가 부족할 때만: 추가로 필요한 질문 1~3개"
                  ]
                }
                
                [근거 작성 규칙]
                - evidence는 1~3개만 작성하라.
                - quote는 컨텍스트에서 발췌한 짧은 문장만. (최대 25단어)
                - 컨텍스트에 근거가 없으면 evidence는 빈 배열([])로 두어라.
                
                [CONTEXT]
                (아래는 검색된 문서 발췌다. 각 항목은 source와 text로 구성된다.)
                {{CONTEXT_BLOCK}}
                
                [QUESTION]
                {{QUESTION}}
                
                """
```


## 배운점

우리가 평소에 사용하는 AI관련 서비스들은 불편함이 크게 느껴 지지않는다. 적은 노력을 들여서 좋은 결과를 얻기 때문이 아닐까? 

하지만 이런 편리함 속에는 많은 노력이 들어간다는 것을 배웠다. 내가 개발하는 서비스를 계속 써보면서 느껴지는 불편함, 혹은 이슈 등을 해결하는 과정에서 초기 설계의 중요성을 계속 배운 기분이였다.

앞으로 개발하게 될 나의 모든 프로젝트에서도 항상 사용자의 입장에서 먼저 생각할것이다.
